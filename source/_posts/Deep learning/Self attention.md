---
title: Self Attention in Transformer Neural Networks
categories: Deep learning
date: 2023-07-04 23:14:35
---

> This will be in three sections
> * Motivation for attention
> * Transformer architecture
> * Self attention with code and maths

> Notes are a summary of the explanation given by [CodeEmporium](https://www.youtube.com/embed/QCJQG4DuHT0)

## Motivation for attention



## Source
<iframe width="560" height="315" src="https://www.youtube.com/embed/QCJQG4DuHT0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>